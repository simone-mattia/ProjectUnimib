{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "57XTTp-OgHsP"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy.io import loadmat\n",
    "from shutil import copyfile\n",
    "from time import time\n",
    "import csv \n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import os \n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n4Cli7O2gaFV",
    "outputId": "0c22f2c3-c11a-4d3c-c935-e975a3d614b2"
   },
   "outputs": [],
   "source": [
    "# ----- Loading the dataset -----\n",
    "\n",
    "#drive.mount('/content/gdrive', force_remount=True)\n",
    "t = time()\n",
    "\n",
    "# Zipped Files\n",
    "for file_name in [\"Annotations\", \"emotic\"]:\n",
    "  if os.path.exists(f'{file_name}/'):\n",
    "    print(f'{file_name} already loaded')\n",
    "  else:\n",
    "    print(f'Loading of {file_name}.zip ...')\n",
    "    if os.path.exists(f'gdrive/MyDrive/FDL_Project/{file_name}.zip'):\n",
    "      # Copy from GDrive to Colab VM\n",
    "      copyfile(f'gdrive/MyDrive/FDL_Project/{file_name}.zip', f'{file_name}.zip')\n",
    "      # Extract files\n",
    "      zip = zipfile.ZipFile(f'{file_name}.zip')\n",
    "      zip.extractall()\n",
    "      zip.close()\n",
    "    else:\n",
    "      print(f'{file_name} not present in Gdrive')\n",
    "\n",
    "# Normal files\n",
    "for file_name in [\"Annotations.json\"]:\n",
    "  if os.path.exists(f'{file_name}'):\n",
    "    print(f'{file_name} already loaded')\n",
    "  else:\n",
    "    print(f'Loading of {file_name}...')\n",
    "    if os.path.exists(f'gdrive/MyDrive/FDL_Project/{file_name}'):\n",
    "      # Copy from GDrive to Colab VM\n",
    "      copyfile(f'gdrive/MyDrive/FDL_Project/{file_name}', f'{file_name}')\n",
    "    else:\n",
    "      print(f'{file_name} not present in Gdrive')\n",
    "print(f'File transfer completed in {round(time() - t, 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BV-Eh1lHuKFY",
    "outputId": "89dce69b-81fc-4d42-b397-afeca1866cfb"
   },
   "outputs": [],
   "source": [
    "# ----- Parsing of the annotations -----\n",
    "\n",
    "class dataset_train:\n",
    "    def __init__(self, filename, folder, image_size, person):\n",
    "        self.filename = filename\n",
    "        self.folder = folder\n",
    "        self.im_size = []\n",
    "        self.bbox = []\n",
    "        self.cat = []\n",
    "        self.cont = []\n",
    "        self.gender = person[3][0]\n",
    "        self.age = person[4][0]\n",
    "        self.cat_annotators = 0\n",
    "        self.cont_annotators = 0\n",
    "        self.set_imsize(image_size)\n",
    "        self.set_bbox(person[0])\n",
    "        self.set_cat(person[1])\n",
    "        self.set_cont(person[2])\n",
    "        self.check_cont()\n",
    "\n",
    "    def set_imsize(self, image_size):\n",
    "        image_size = np.array(image_size).flatten().tolist()[0]\n",
    "        row = np.array(image_size[0]).flatten().tolist()[0]\n",
    "        col = np.array(image_size[1]).flatten().tolist()[0]\n",
    "        self.im_size.append(row)\n",
    "        self.im_size.append(col)\n",
    "\n",
    "    def validate_bbox(self, bbox):\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        x1 = min(self.im_size[0], max(0, x1))\n",
    "        x2 = min(self.im_size[0], max(0, x2))\n",
    "        y1 = min(self.im_size[1], max(0, y1))\n",
    "        y2 = min(self.im_size[1], max(0, y2))\n",
    "        return [int(x1), int(y1), int(x2), int(y2)]\n",
    "\n",
    "    def set_bbox(self, person_bbox):\n",
    "        self.bbox = self.validate_bbox(np.array(person_bbox).flatten().tolist())\n",
    "\n",
    "    def set_cat(self, person_cat):\n",
    "        cat = np.array(person_cat).flatten().tolist()\n",
    "        cat = np.array(cat[0]).flatten().tolist()\n",
    "        self.cat = [np.array(c).flatten().tolist()[0] for c in cat]\n",
    "        self.cat_annotators = 1\n",
    "\n",
    "    def set_cont(self, person_cont):\n",
    "        cont = np.array(person_cont).flatten().tolist()[0]\n",
    "        self.cont = [np.array(c).flatten().tolist()[0] for c in cont]\n",
    "        self.cont_annotators = 1\n",
    "\n",
    "    def check_cont(self):\n",
    "        for c in self.cont:\n",
    "            if np.isnan(c):\n",
    "                self.cont_annotators = 0\n",
    "                break\n",
    "\n",
    "class dataset_test:\n",
    "    def __init__(self, filename, folder, image_size, person):\n",
    "        self.filename = filename\n",
    "        self.folder = folder\n",
    "        self.im_size = []\n",
    "        self.bbox = []\n",
    "        self.cat = []\n",
    "        self.cat_annotators = 0\n",
    "        self.comb_cat = []\n",
    "        self.cont_annotators = 0\n",
    "        self.cont = []\n",
    "        self.comb_cont = []\n",
    "        self.gender = person[5][0]\n",
    "        self.age = person[6][0]\n",
    "\n",
    "        self.set_imsize(image_size)\n",
    "        self.set_bbox(person[0])\n",
    "        self.set_cat(person[1])\n",
    "        self.set_comb_cat(person[2])\n",
    "        self.set_cont(person[3])\n",
    "        self.set_comb_cont(person[4])\n",
    "        self.check_cont()\n",
    "\n",
    "    def set_imsize(self, image_size):\n",
    "        image_size = np.array(image_size).flatten().tolist()[0]\n",
    "        row = np.array(image_size[0]).flatten().tolist()[0]\n",
    "        col = np.array(image_size[1]).flatten().tolist()[0]\n",
    "        self.im_size.append(row)\n",
    "        self.im_size.append(col)\n",
    "\n",
    "    def validate_bbox(self, bbox):\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        x1 = min(self.im_size[0], max(0, x1))\n",
    "        x2 = min(self.im_size[0], max(0, x2))\n",
    "        y1 = min(self.im_size[1], max(0, y1))\n",
    "        y2 = min(self.im_size[1], max(0, y2))\n",
    "        return [int(x1), int(y1), int(x2), int(y2)]\n",
    "\n",
    "    def set_bbox(self, person_bbox):\n",
    "        self.bbox = self.validate_bbox(np.array(person_bbox).flatten().tolist())\n",
    "\n",
    "    def set_cat(self, person_cat):\n",
    "        self.cat_annotators = len(person_cat[0])\n",
    "        for ann in range(self.cat_annotators):\n",
    "            ann_cat = person_cat[0][ann]\n",
    "            ann_cat = np.array(ann_cat).flatten().tolist()\n",
    "            ann_cat = np.array(ann_cat[0]).flatten().tolist()\n",
    "            ann_cat = [np.array(c).flatten().tolist()[0] for c in ann_cat]\n",
    "            self.cat.append(ann_cat)\n",
    "\n",
    "    def set_comb_cat(self, person_comb_cat):\n",
    "        if self.cat_annotators != 0:\n",
    "            self.comb_cat = [np.array(c).flatten().tolist()[0] for c in person_comb_cat[0]]\n",
    "        else:\n",
    "            self.comb_cat = []\n",
    "\n",
    "    def set_comb_cont(self, person_comb_cont):\n",
    "        if self.cont_annotators != 0:\n",
    "            comb_cont = [np.array(c).flatten().tolist()[0] for c in person_comb_cont[0]]\n",
    "            self.comb_cont = [np.array(c).flatten().tolist()[0] for c in comb_cont[0]]\n",
    "        else:\n",
    "            self.comb_cont = []\n",
    "\n",
    "    def set_cont(self, person_cont):\n",
    "        self.cont_annotators = len(person_cont[0])\n",
    "        for ann in range(self.cont_annotators):\n",
    "            ann_cont = person_cont[0][ann]\n",
    "            ann_cont = np.array(ann_cont).flatten().tolist()\n",
    "            ann_cont = np.array(ann_cont[0]).flatten().tolist()\n",
    "            ann_cont = [np.array(c).flatten().tolist()[0] for c in ann_cont]\n",
    "            self.cont.append(ann_cont)\n",
    "\n",
    "    def check_cont(self):\n",
    "        for c in self.comb_cont:\n",
    "            if np.isnan(c):\n",
    "                self.cont_annotators = 0\n",
    "                break\n",
    "\n",
    "save_path = 'emotic/parsed'\n",
    "if not os.path.exists(save_path):\n",
    "  os.makedirs(save_path)\n",
    "\n",
    "cat = ['Affection', 'Anger', 'Annoyance', 'Anticipation', 'Aversion', 'Confidence', 'Disapproval', 'Disconnection',\n",
    "    'Disquietment', 'Doubt/Confusion', 'Embarrassment', 'Engagement', 'Esteem', 'Excitement', 'Fatigue', 'Fear',\n",
    "    'Happiness', 'Pain', 'Peace', 'Pleasure', 'Sadness', 'Sensitivity', 'Suffering', 'Surprise', 'Sympathy', 'Yearning']\n",
    "\n",
    "cat2ind = {}\n",
    "ind2cat = {}\n",
    "\n",
    "for idx, emotion in enumerate(cat):\n",
    "    cat2ind[emotion] = idx\n",
    "    ind2cat[idx] = emotion\n",
    "\n",
    "print ('Loading annotations...')\n",
    "t = time()\n",
    "if os.path.exists('Annotations.json'):\n",
    "    print ('Annotations already loaded')\n",
    "else:\n",
    "  mat = loadmat('Annotations/Annotations.mat')\n",
    "  labels = ['train', 'val', 'test']\n",
    "  for label in labels:\n",
    "    if os.path.exists(f'emotic/parsed/{label}.csv'):\n",
    "      print (f'Label {label} already loaded')\n",
    "    else:\n",
    "      data_mat = mat[label]\n",
    "      print (f'Loading label {label}')\n",
    "      data_set = list()\n",
    "      to_break = 0\n",
    "      path_not_exist = 0\n",
    "      cat_cont_zero = 0\n",
    "      idx = 0\n",
    "      for ex_idx, ex in enumerate(data_mat[0]):\n",
    "        nop = len(ex[4][0])\n",
    "        for person in range(nop):\n",
    "          if label == 'train':\n",
    "            et = dataset_train(ex[0][0],ex[1][0],ex[2],ex[4][0][person])\n",
    "          else:\n",
    "            et = dataset_test(ex[0][0],ex[1][0],ex[2],ex[4][0][person])\n",
    "          try:\n",
    "            image_path = os.path.join('emotic/',et.folder,et.filename)\n",
    "            if not os.path.exists(image_path):\n",
    "              path_not_exist += 1\n",
    "              print ('path not existing', ex_idx, image_path)\n",
    "              continue\n",
    "            else:\n",
    "              context = cv2.cvtColor(cv2.imread(image_path),cv2.COLOR_BGR2RGB)\n",
    "              body = context[et.bbox[1]:et.bbox[3],et.bbox[0]:et.bbox[2]].copy()\n",
    "              context_cv = cv2.resize(context, (224,224))\n",
    "              body_cv = cv2.resize(body, (128,128))\n",
    "          except Exception as e:\n",
    "            to_break += 1\n",
    "            continue\n",
    "          if (et.cat_annotators == 0 or et.cont_annotators == 0):\n",
    "            cat_cont_zero += 1\n",
    "            continue\n",
    "          data_set.append(et)\n",
    "          idx += 1  \n",
    "          if idx % 1000 == 0:\n",
    "            print (\" Preprocessing data. Index = \", idx)\n",
    "      print (to_break, path_not_exist, cat_cont_zero)\n",
    "      \n",
    "      csv_path = os.path.join(save_path, \"%s.csv\" %(label))\n",
    "      with open(csv_path, 'w') as csvfile:\n",
    "        filewriter = csv.writer(csvfile, delimiter=',', dialect='excel')\n",
    "        row = ['Index', 'Folder', 'Filename', 'Image Size', 'BBox', 'Categorical_Labels', 'Continuous_Labels', 'Gender', 'Age']\n",
    "        filewriter.writerow(row)\n",
    "        for idx, ex in enumerate(data_set):\n",
    "            if label == 'train':\n",
    "                row = [idx, ex.folder, ex.filename, ex.im_size, ex.bbox, ex.cat, ex.cont, ex.gender, ex.age]\n",
    "            else:\n",
    "                row = [idx, ex.folder, ex.filename, ex.im_size, ex.bbox, ex.comb_cat, ex.comb_cont, ex.gender, ex.age]\n",
    "            filewriter.writerow(row)\n",
    "      print ('wrote file ', csv_path)\n",
    "      print ('completed generating %s data files' %(label))\n",
    "\n",
    "print(f'Annotation loading completed in {round(time() - t, 2)} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_2zTxrj-8WvB"
   },
   "outputs": [],
   "source": [
    "# ----- Print Images with Annotations -----\n",
    "\n",
    "def parse_categories(labels):\n",
    "    categories = [0 for i in range(26)]\n",
    "    for x in labels:\n",
    "        categories[cat2ind[x]]=1\n",
    "    return categories\n",
    "\n",
    "def parse_index_from_cat(labels):\n",
    "    categories = []\n",
    "    for idx,i in enumerate(labels):\n",
    "        if(i)>0.1:\n",
    "            categories.append(ind2cat[idx])\n",
    "    return categories\n",
    "\n",
    "def printImage(bboxes, labels, img, scaled=True, resnet=False, size = [], label_mode=False):\n",
    "\n",
    "  # Plot figure\n",
    "  fig = plt.figure()\n",
    "  \n",
    "  # add axes to the image\n",
    "  ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "  # read and plot the image\n",
    "  if isinstance(img, str):\n",
    "    img = plt.imread(img) \n",
    "\n",
    "  height = img.shape[0]\n",
    "  width = img.shape[1]\n",
    "  if size != []:\n",
    "    height = size[0]\n",
    "    width = size[1]\n",
    "  \n",
    "  plt.imshow(img)\n",
    "  for i in range(len(bboxes)):\n",
    "    #print(bboxes[i])\n",
    "    bbox = bboxes[i]\n",
    "    if isinstance(bbox, str):\n",
    "      bbox = [float(x) for x in bbox[1:-1].split(',')]\n",
    "\n",
    "    ymin, xmin, ymax, xmax, w, h = [0,0,0,0,0,0]\n",
    "\n",
    "    if scaled:\n",
    "      if resnet:\n",
    "        bbox[1] *= width\n",
    "        bbox[2] *= height\n",
    "        bbox[3] *= width\n",
    "        bbox[0] *= height\n",
    "        ymin, xmin, ymax, xmax = bbox\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "      else:\n",
    "        bbox[0] *= width\n",
    "        bbox[1] *= height\n",
    "        bbox[2] *= width\n",
    "        bbox[3] *= height\n",
    "        xmin, ymin, xmax, ymax = bbox\n",
    "        w = xmax - xmin\n",
    "        h = ymax - ymin\n",
    "    else:\n",
    "      xmin, ymin, xmax, ymax = bbox\n",
    "      w = xmax - xmin\n",
    "      h = ymax - ymin\n",
    "\n",
    "    # add bounding boxes to the image\n",
    "    box = Rectangle(\n",
    "        (xmin, ymin), w, h, edgecolor=\"red\", facecolor=\"none\"\n",
    "    )\n",
    "\n",
    "    ax.add_patch(box)\n",
    "\n",
    "    rx, ry = box.get_xy()\n",
    "    cx = rx + box.get_width()/2.0\n",
    "    cy = ry + box.get_height()/8.0\n",
    "\n",
    "    box_label = labels[i]\n",
    "    if label_mode:\n",
    "      box_label = parse_index_from_cat(labels[i])\n",
    "\n",
    "    l = ax.annotate(\n",
    "      box_label,\n",
    "      (cx, cy),\n",
    "      fontsize=8,\n",
    "      fontweight=\"bold\",\n",
    "      color=\"white\",\n",
    "      ha='center',\n",
    "      va='center'\n",
    "    )\n",
    "    l.set_bbox(\n",
    "      dict(facecolor='red', alpha=0.5, edgecolor='red')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hIlK78x9zQu6",
    "outputId": "9c7c886d-d599-4d4d-e79c-15a77c0ece6c"
   },
   "outputs": [],
   "source": [
    "# ----- Annotation Parsing Pt.2 -----\n",
    "\n",
    "MAX_BOX = 1\n",
    "\n",
    "annotation = {\n",
    "    \"train\": [],\n",
    "    \"val\": [],\n",
    "    \"test\": [],\n",
    "}\n",
    "\n",
    "limit = {\n",
    "  \"val\": 1300,\n",
    "  \"train\": 5000,\n",
    "  \"test\": 1300\n",
    "}\n",
    "\n",
    "if os.path.exists('Annotations.json'):\n",
    "    with open('Annotations.json', 'r') as openfile:\n",
    "      annotation = json.load(openfile)\n",
    "    print('Annotations already loaded')\n",
    "    #for x in [random.randint(0, len(annotation[label])) for x in range(1)]:\n",
    "      #printImage([annotation[label][x][\"bbox\"]], annotation[label][x][\"label\"], annotation[label][x][\"path\"]) \n",
    "else:\n",
    "  for label in [\"val\", \"train\", \"test\"]:\n",
    "\n",
    "    # Group dataset by image path\n",
    "    image_dataframe = pd.read_csv(f'emotic/parsed/{label}.csv')\n",
    "    image_dataframe[\"image_path\"] = image_dataframe.apply(lambda x: os.path.join('emotic',x['Folder'], x['Filename']), axis=1)\n",
    "    categories = image_dataframe.groupby(\"image_path\")['Categorical_Labels'].apply(list)\n",
    "    continuous_labels = image_dataframe.groupby(\"image_path\")['Continuous_Labels'].apply(list)\n",
    "    image_dataframe = pd.DataFrame(image_dataframe.groupby(\"image_path\")['BBox'].apply(list))\n",
    "    image_dataframe = image_dataframe.rename(columns={\"BBox\":\"bbox\"})\n",
    "    image_dataframe['label'] = categories\n",
    "    image_dataframe['continuous_labels'] = continuous_labels\n",
    "    #display(image_dataframe)  \n",
    "\n",
    "    # Parse to python array\n",
    "    count = 0\n",
    "    for index, row in  image_dataframe.iterrows():\n",
    "      if len(row[\"bbox\"]) <= MAX_BOX and len(row[\"label\"]) <= MAX_BOX and len(row[\"continuous_labels\"]) <= MAX_BOX:\n",
    "        img = plt.imread(row.name)\n",
    "        height = img.shape[0]\n",
    "        width = img.shape[1]\n",
    "        new_bboxes = []\n",
    "        new_cont_labels = []\n",
    "        new_labels = []\n",
    "        for index,element in enumerate(row[\"bbox\"]):\n",
    "            df_bbox = element\n",
    "            bbox = [float(x) for x in df_bbox[1:-1].split(',')]\n",
    "            bbox[0] /= width\n",
    "            bbox[1] /= height\n",
    "            bbox[2] /= width\n",
    "            bbox[3] /= height\n",
    "            if len([x for x in bbox if 0 <= x <= 1]) == 4:\n",
    "              new_bboxes.append(bbox)\n",
    "              new_cont_labels.append([float(x)/10 for x in row[\"continuous_labels\"][index][1:-1].split(',')])\n",
    "              new_labels.append([x for x in row[\"label\"][index][1:-1].replace(\" \", \"\").replace(\"'\", \"\").split(',')])\n",
    "        if len(new_bboxes)<MAX_BOX:\n",
    "            box_to_add=MAX_BOX-len(new_bboxes)\n",
    "            for i in range(box_to_add):\n",
    "                new_bboxes.append([0.0,0.0,0.0,0.0])\n",
    "                new_cont_labels.append([0.0,0.0,0.0])\n",
    "                new_labels.append([])\n",
    "        count += 1\n",
    "        if count > limit[label]:\n",
    "            break\n",
    "        else:\n",
    "            annotation[label].append({\n",
    "                \"path\": row.name,\n",
    "                \"bbox\": new_bboxes,\n",
    "                \"continuous_labels\": new_cont_labels,\n",
    "                \"label\": new_labels\n",
    "            })\n",
    "\n",
    "    print(f\"Dataset {label} lenght post sampling: {len(annotation[label])}\")\n",
    "    #display(annotation[label][0])\n",
    "    print()\n",
    "  \n",
    "  blacklist = [set(x[\"path\"] for x in annotation[\"train\"]).intersection(set(x[\"path\"] for x in annotation[\"val\"]))]\n",
    "  blacklist += [set(x[\"path\"] for x in annotation[\"test\"]).intersection(set(x[\"path\"] for x in annotation[\"val\"]))]\n",
    "  blacklist += [set(x[\"path\"] for x in annotation[\"train\"]).intersection(set(x[\"path\"] for x in annotation[\"test\"]))]\n",
    "  for label in [\"val\", \"train\", \"test\"]:\n",
    "    annotation[label] = [x for x in annotation[label] if x[\"path\"] not in blacklist]\n",
    "\n",
    "  print(f\"\\nRemoved {len(blacklist)} images for incorrect annotations\")\n",
    "\n",
    "  with open(\"Annotations.json\", \"w\") as outfile:\n",
    "    outfile.write(json.dumps(annotation, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CFraxqlM_Apv",
    "outputId": "eaa11634-d4de-4588-8759-f440e7980edb"
   },
   "outputs": [],
   "source": [
    "# ----- Tensorflow Dataset V2 ------\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "IMG_SIZE = (224, 224)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "\n",
    "STR_LABEL = False\n",
    "\n",
    "dataset = {\n",
    "    \"train\": None,\n",
    "    \"val\": None,\n",
    "    \"test\": None,\n",
    "}\n",
    "\n",
    "def read_image_bbox(path, bbox, label):\n",
    "    path = path.decode()\n",
    "    image = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "    image = cv2.resize(image, (IMG_SIZE[1], IMG_SIZE[0]))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = image / 255.0\n",
    "\n",
    "    image = image.astype(np.float32)\n",
    "    norm_bbox = np.array(bbox, dtype=np.float32)\n",
    "    categories = np.array(label, dtype=np.float32)\n",
    "\n",
    "    return image, norm_bbox, categories\n",
    "\n",
    "def parse(image, bbox, label):\n",
    "    image,bbox,label = tf.numpy_function(read_image_bbox, [image,bbox,label], [tf.float32, tf.float32, tf.float32])\n",
    "    image.set_shape([IMG_SIZE[0], IMG_SIZE[1], 3])\n",
    "    bbox.set_shape([MAX_BOX,4])\n",
    "    if STR_LABEL:\n",
    "      label.set_shape([MAX_BOX,len(cat)])\n",
    "    else:\n",
    "      label.set_shape([MAX_BOX,3])\n",
    "    return (image), (bbox, label)\n",
    "\n",
    "for label in [\"val\", \"train\", \"test\"]:\n",
    "\n",
    "  print(f\"Annotation dataset {label} lenght post sampling: {len(annotation[label])}\")\n",
    "  \n",
    "\n",
    "  def lambda_label(x):\n",
    "    out = []\n",
    "    for y in x[\"label\"]:\n",
    "       out.append(parse_categories(y))\n",
    "    return out\n",
    "      \n",
    "  #lambda_label = lambda x: [parse_categories(y) y for y in x[\"label\"]]\n",
    "\n",
    "  if not STR_LABEL:\n",
    "    lambda_label = lambda x: x[\"continuous_labels\"]\n",
    "\n",
    "  dataset[label] = tf.data.Dataset.from_tensor_slices((\n",
    "        [x[\"path\"] for x in annotation[label]],\n",
    "        [x[\"bbox\"] for x in annotation[label]],\n",
    "        [lambda_label(x) for x in annotation[label]]\n",
    "  ))\n",
    "\n",
    "  dataset[label] = dataset[label].map(parse)\n",
    "\n",
    "  for n, image in enumerate(dataset[label].take(1)):\n",
    "    printImage(image[1][0].numpy(), image[1][1].numpy(), image[0], label_mode=STR_LABEL)\n",
    "\n",
    "  dataset[label] = dataset[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pqo7uoiujsTw",
    "outputId": "fa0d021b-b4b8-41cc-9ff5-bfd0bd3ecb6d"
   },
   "outputs": [],
   "source": [
    "#  ----- Network Architecture ----- \n",
    "\n",
    "tf.keras.utils.set_random_seed(12345)\n",
    "\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "base_model.trainable = False\n",
    "#base_model.summary()\n",
    "\n",
    "inputs = tf.keras.Input(IMG_SHAPE)\n",
    "#x = tf.keras.applications.mobilenet_v2.preprocess_input(inputs)\n",
    "x = base_model(inputs, training=False)\n",
    "#x = tf.keras.layers.Conv2D(256, kernel_size=1, padding=\"same\")(x)\n",
    "#x = tf.keras.layers.BatchNormalization()(x)\n",
    "#x = tf.keras.layers.Activation(\"relu\")(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "#x = tf.keras.layers.Dropout(0.3)(x)\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "bbox = tf.keras.layers.Dense(MAX_BOX*4, activation=\"sigmoid\")(x) \n",
    "bbox=tf.keras.layers.Reshape((MAX_BOX,4),name=\"bbox\")(bbox)\n",
    "labels = tf.keras.layers.Dense((MAX_BOX*3), activation=\"sigmoid\")(x)\n",
    "labels=tf.keras.layers.Reshape((MAX_BOX,3),name=\"label\")(labels) \n",
    "if STR_LABEL:\n",
    "    labels = tf.keras.layers.Dense((MAX_BOX*len(cat)), activation=\"sigmoid\")(x) \n",
    "    labels=tf.keras.layers.Reshape((MAX_BOX,len(cat)),name=\"label\")(labels)\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[bbox,labels]) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rQbu8co4NeXi",
    "outputId": "d967504a-ccb2-4215-d53b-f9a6a522365e"
   },
   "outputs": [],
   "source": [
    "# ----- Training for the top layers -----\n",
    "\n",
    "\n",
    "initial_epochs = 10\n",
    "base_learning_rate = 0.001\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"freeze.h5\", verbose=1, save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-8, verbose=1),\n",
    "]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(base_learning_rate),\n",
    "              #run_eagerly=True,\n",
    "              loss={\n",
    "                  \"bbox\": tf.keras.losses.MeanSquaredError(), #tfa.losses.GIoULoss()\n",
    "                  \"label\": tf.keras.losses.CategoricalCrossentropy() if STR_LABEL  else tf.keras.losses.MeanSquaredError()})\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    dataset[\"train\"].batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE),\n",
    "    epochs=initial_epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_data=dataset[\"val\"].batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "initial_epochs = len(history.history[\"loss\"]) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "u3RF7lY7oZMc",
    "outputId": "1a97547c-2571-4b84-b3f3-a201b45d2545"
   },
   "outputs": [],
   "source": [
    "# ----- Plot Train/Val Loss -----\n",
    "\n",
    "loss = [x for x in history.history['loss']]\n",
    "val_loss = [x for x in history.history['val_loss']]\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Loss')\n",
    "#plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6eavPGxpePam",
    "outputId": "64ad8145-fcb2-4a3b-8ddf-1392f9bead3d"
   },
   "outputs": [],
   "source": [
    "# ----- Plot Random Prediction -----\n",
    "\n",
    "def run_detector(detector, path, test=False, box=[], label=[]):\n",
    "  image = cv2.imread(path, cv2.IMREAD_UNCHANGED)\n",
    "  image = cv2.resize(image, (IMG_SIZE[1], IMG_SIZE[0]))\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "  image = image / 255.0\n",
    "  image = image.astype(np.float32)\n",
    "  converted_img  = tf.image.convert_image_dtype(image, tf.float32)[tf.newaxis, ...]\n",
    "  result = detector(converted_img)\n",
    "  #print(result[0][0].numpy())\n",
    "  if test:\n",
    "    if label != []:\n",
    "      result_labels = []\n",
    "      for i in range(len(label)):\n",
    "        if STR_LABEL:\n",
    "          result_labels.append(parse_index_from_cat(result[1][0].numpy()[i]))\n",
    "        else:\n",
    "          #print(result[1][0].numpy()[i])\n",
    "          result_labels.append([round(x,1) for x in result[1][0].numpy()[i]])\n",
    "        #print(result[1][0].numpy()[i])\n",
    "        #print(result_labels)\n",
    "      printImage(result[0][0].numpy(), result_labels, path)\n",
    "      printImage(box, label, path)\n",
    "    else:\n",
    "      printImage(result[0][0].numpy(), [\"\" for x in range(MAX_BOX)], path)\n",
    "      printImage(box, [\"\" for x in range(MAX_BOX)], path)\n",
    "  else:\n",
    "    printImage(result[0][0].numpy(), result[1][0].numpy(), path)\n",
    "\n",
    "model.load_weights(\"freeze.h5\")\n",
    "\n",
    "n = random.randint(0, len(annotation[\"val\"]))\n",
    "n = annotation[\"val\"][n]\n",
    "#result = model.predict(tf.reshape(image[0], (1, 224, 224, 3)))\n",
    "#print(n[\"path\"])\n",
    "result=run_detector(model,n[\"path\"], test=True, box=n[\"bbox\"], label=n[\"label\"] if STR_LABEL else n[\"continuous_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZyZuPnMv6-EQ"
   },
   "outputs": [],
   "source": [
    "# ----- Fine Tuning -----\n",
    "\n",
    "base_model.trainable = True\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 100\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False\n",
    "\n",
    "#model_fine = tf.keras.Model(inputs=[inputs], outputs=[bbox,labels])\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\"finetune.h5\", verbose=1, save_best_only=True),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, min_lr=1e-8, verbose=1),\n",
    "]\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(base_learning_rate/10), \n",
    "                   loss={\n",
    "                        \"bbox\": tf.keras.losses.MeanSquaredError(), #tfa.losses.GIoULoss()\n",
    "                        \"label\": tf.keras.losses.CategoricalCrossentropy() if STR_LABEL  else tf.keras.losses.MeanSquaredError()\n",
    "                    })\n",
    "\n",
    "\n",
    "fine_tune_epochs = int(initial_epochs/2)\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(dataset[\"train\"].batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE),\n",
    "                         epochs=total_epochs,\n",
    "                         callbacks=callbacks,\n",
    "                         initial_epoch=history.epoch[-1],\n",
    "                         validation_data=dataset[\"val\"].batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ktt_P_QB7Poh"
   },
   "outputs": [],
   "source": [
    "# ----- Plot Train/Val Loss -----\n",
    "\n",
    "loss += [x for x in history_fine.history['loss']]\n",
    "val_loss += [x for x in history_fine.history['val_loss']]\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "#plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs-1,initial_epochs-1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqO2YgzADKBs"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"finetune.h5\")\n",
    "\n",
    "n = random.randint(0, len(annotation[\"val\"]))\n",
    "n = annotation[\"val\"][n]\n",
    "#result = model.predict(tf.reshape(image[0], (1, 224, 224, 3)))\n",
    "#print(n[\"path\"])\n",
    "result=run_detector(model,n[\"path\"], test=True, box=n[\"bbox\"], label=n[\"label\"] if STR_LABEL else n[\"continuous_labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Evaluation -----\n",
    "\n",
    "model.load_weights(\"finetune.h5\")\n",
    "\n",
    "results = model.evaluate(dataset[\"test\"].batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE))\n",
    "print(model.metrics_names)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
